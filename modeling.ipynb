{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python_defaultSpec_1598650116917",
      "display_name": "Python 3.7.6 64-bit ('base': conda)"
    },
    "colab": {
      "name": "modeling.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23Ef-9waSl_Q",
        "colab_type": "text"
      },
      "source": [
        "# Building a Generative Music Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7J2G_b4Sl_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTEsmVBsSl_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('processed_data/vectorized_classical_songs2.npy', 'rb') as data:\n",
        "    songs = np.load(data, allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "lCw_WnrMSl_b",
        "colab_type": "code",
        "colab": {},
        "outputId": "fea87f0a-1d37-46e4-b414-35c522abbcbb"
      },
      "source": [
        "print(f'# of songs in dataset: {len(songs):,}')\n",
        "print(f'avg # of notes per song: {np.average(list(map(len, songs[:,0]))):.0f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of songs in dataset: 3,013\n",
            "avg # of notes per song: 2664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzjkeC5JSl_h",
        "colab_type": "code",
        "colab": {},
        "outputId": "8514f745-8773-4dd4-89e6-d57dec4979a3"
      },
      "source": [
        "songs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3013, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFDj_9s3Sl_l",
        "colab_type": "text"
      },
      "source": [
        "## Create Training Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "gNfJ3kfzSl_l",
        "colab_type": "code",
        "colab": {},
        "outputId": "701c0db3-fb49-4243-d460-6f502b811b95"
      },
      "source": [
        "Xs_p = []\n",
        "Xs_d = []\n",
        "\n",
        "Ys_p = []\n",
        "Ys_d = []\n",
        "\n",
        "for song in tqdm(songs):\n",
        "    song_pitches = song[0]\n",
        "    song_durs = song[1]\n",
        "    \n",
        "    X_p, Y_p = utils.get_sequences(song_pitches, input_length=32, output_length=1, offset=1, shift=1)\n",
        "    X_d, Y_d = utils.get_sequences(song_durs, input_length=32, output_length=1, offset=1, shift=1)\n",
        "\n",
        "    if X_p.ndim != 1:\n",
        "        Xs_p.append(X_p)\n",
        "        Xs_d.append(X_d)\n",
        "        \n",
        "        Ys_p.append(Y_p)\n",
        "        Ys_d.append(Y_d)\n",
        "        \n",
        "\n",
        "X_p = np.concatenate(Xs_p)\n",
        "X_d = np.concatenate(Xs_d)\n",
        "\n",
        "Y_p = np.concatenate(Ys_p)\n",
        "Y_d = np.concatenate(Ys_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3013/3013 [15:34:21<00:00, 18.61s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "DiJtPtC9Sl_p",
        "colab_type": "code",
        "colab": {},
        "outputId": "1a5978ae-911a-4c08-be23-8a81b77bb098"
      },
      "source": [
        "print(f'X_p shape: {X_p.shape}')\n",
        "print(f'X_d shape: {X_d.shape}')\n",
        "print()\n",
        "print(f'Y_p shape: {Y_p.shape}')\n",
        "print(f'Y_d shape: {Y_d.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_p shape: (7928979, 32)\n",
            "X_d shape: (7928979, 32)\n",
            "\n",
            "Y_p shape: (7928979, 1)\n",
            "Y_d shape: (7928979, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXnX1fhDSl_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savez_compressed('processed_data/classical_songs_sequences.npz', X=(X_p, X_d), Y=(Y_p, Y_d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdXfJvISl_y",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE7jsZQcZUwO",
        "colab_type": "text"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdOBGrZJSl_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.load('processed_data/classical_songs_sequences.npz', mmap_mode='r')\n",
        "X = data['X'] # (X_p, X_d)\n",
        "Y = data['Y'] # (Y_p, Y_d)\n",
        "\n",
        "X_p, X_d = X[0], X[1]\n",
        "Y_p, Y_d = Y[0], Y[1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "2zYeXvqrSl_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a31e5a9a-eb7e-427f-a0f6-689536821f64"
      },
      "source": [
        "print(f'there are {X_p.shape[0]:,} sequences of {X_p.shape[1]} notes for training')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 7,928,979 sequences of 32 notes for training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpS9zkZtSl_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert targets to one hot encoding \n",
        "Y_p_ohe, Y_d_ohe = tf.keras.utils.to_categorical(np.squeeze(Y_p)), tf.keras.utils.to_categorical(np.squeeze(Y_d))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egz63fQ9SmAG",
        "colab_type": "text"
      },
      "source": [
        "### Model1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "JGCXBAUPSmAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Concatenate, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DSxbkuRSmAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# constants\n",
        "n_pitches = 12\n",
        "n_durs = 5\n",
        "seq_len = X_p.shape[1] \n",
        "\n",
        "# hyperparameters\n",
        "embed_dim = 12 \n",
        "lstm1_n_units = 512\n",
        "dense1_n_units = 256"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4hJOijlSmAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define input layers\n",
        "pitch_input = Input(shape=(None, ), name='pitch_input')\n",
        "dur_input = Input(shape=(None, ), name='dur_input')\n",
        "\n",
        "# Define embedding layers\n",
        "pitch_embedding = Embedding(n_pitches, embed_dim, name='pitch_emb')(pitch_input)\n",
        "dur_embedding = Embedding(n_durs, embed_dim, name='dur_emb')(dur_input) \n",
        "\n",
        "# Merge embedding layers using a concatenation layer\n",
        "pitch_dur = Concatenate(axis=1, name='merge_pitch_dur')([pitch_embedding, dur_embedding])\n",
        "\n",
        "# Define LSTM layer\n",
        "lstm1 = LSTM(lstm1_n_units, name='lstm1')(pitch_dur)\n",
        "\n",
        "# Define dense layer\n",
        "dense1 = Dense(dense1_n_units, name='dense1')(lstm1)\n",
        "\n",
        "# Define output layers\n",
        "pitch_output = Dense(n_pitches, activation='softmax', name='pitch_output')(dense1)\n",
        "dur_output = Dense(n_durs, activation='softmax', name='dur_output')(dense1)\n",
        "\n",
        "# Define model\n",
        "model1 = tf.keras.Model(inputs=[pitch_input, dur_input], outputs=[pitch_output, dur_output], name='model1')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "AusPAtHqSmAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "05cf3ba3-4b01-41c6-ccec-165356c92b73"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "pitch_input (InputLayer)        [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dur_input (InputLayer)          [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "pitch_emb (Embedding)           (None, None, 12)     144         pitch_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dur_emb (Embedding)             (None, None, 12)     60          dur_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "merge_pitch_dur (Concatenate)   (None, None, 12)     0           pitch_emb[0][0]                  \n",
            "                                                                 dur_emb[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm1 (LSTM)                    (None, 512)          1075200     merge_pitch_dur[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 256)          131328      lstm1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pitch_output (Dense)            (None, 12)           3084        dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dur_output (Dense)              (None, 5)            1285        dense1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,211,101\n",
            "Trainable params: 1,211,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7PEcDvcSmAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam()\n",
        "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "CICMJrjFSmAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "0b0774f5-4ec4-4649-9fc1-5472eb569725"
      },
      "source": [
        "# dataset very large so step_per_epoch is reduced\n",
        "# TODO: currently the train-val split results in data leakage, that's okay for now, but a split on the song-level would solve that\n",
        "history = model1.fit(x=[X_p, X_d], y=[Y_p_ohe, Y_d_ohe], validation_split=0.01, batch_size=64, steps_per_epoch=8000, epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "8000/8000 [==============================] - 132s 16ms/step - loss: 2.5467 - pitch_output_loss: 1.8820 - dur_output_loss: 0.6646 - pitch_output_accuracy: 0.3615 - dur_output_accuracy: 0.7535 - val_loss: 2.2149 - val_pitch_output_loss: 1.5793 - val_dur_output_loss: 0.6356 - val_pitch_output_accuracy: 0.5007 - val_dur_output_accuracy: 0.7681\n",
            "Epoch 2/5\n",
            "8000/8000 [==============================] - 131s 16ms/step - loss: 2.4455 - pitch_output_loss: 1.7885 - dur_output_loss: 0.6570 - pitch_output_accuracy: 0.3970 - dur_output_accuracy: 0.7577 - val_loss: 2.1707 - val_pitch_output_loss: 1.5417 - val_dur_output_loss: 0.6291 - val_pitch_output_accuracy: 0.5134 - val_dur_output_accuracy: 0.7667\n",
            "Epoch 3/5\n",
            "8000/8000 [==============================] - 131s 16ms/step - loss: 2.4047 - pitch_output_loss: 1.7504 - dur_output_loss: 0.6544 - pitch_output_accuracy: 0.4094 - dur_output_accuracy: 0.7588 - val_loss: 2.1515 - val_pitch_output_loss: 1.5234 - val_dur_output_loss: 0.6281 - val_pitch_output_accuracy: 0.5167 - val_dur_output_accuracy: 0.7700\n",
            "Epoch 4/5\n",
            "8000/8000 [==============================] - 131s 16ms/step - loss: 2.3808 - pitch_output_loss: 1.7304 - dur_output_loss: 0.6504 - pitch_output_accuracy: 0.4155 - dur_output_accuracy: 0.7611 - val_loss: 2.1204 - val_pitch_output_loss: 1.4992 - val_dur_output_loss: 0.6212 - val_pitch_output_accuracy: 0.5259 - val_dur_output_accuracy: 0.7704\n",
            "Epoch 5/5\n",
            "8000/8000 [==============================] - 131s 16ms/step - loss: 2.3547 - pitch_output_loss: 1.7113 - dur_output_loss: 0.6434 - pitch_output_accuracy: 0.4229 - dur_output_accuracy: 0.7626 - val_loss: 2.1196 - val_pitch_output_loss: 1.4987 - val_dur_output_loss: 0.6209 - val_pitch_output_accuracy: 0.5267 - val_dur_output_accuracy: 0.7737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gThFC2osZHZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.save('model1_1.h5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4CtgDQjZcPW",
        "colab_type": "text"
      },
      "source": [
        "### Model2: Add second LSTM layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ8E7XxNZePc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# constants\n",
        "n_pitches = 12\n",
        "n_durs = 5\n",
        "seq_len = X_p.shape[1] \n",
        "\n",
        "# hyperparameters\n",
        "embed_dim = 12 \n",
        "lstm1_n_units = 128\n",
        "lstm2_n_units = 64\n",
        "dense1_n_units = 32"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsfXmBcsZiOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define input layers\n",
        "pitch_input = Input(shape=(None, ), name='pitch_input')\n",
        "dur_input = Input(shape=(None, ), name='dur_input')\n",
        "\n",
        "# Define embedding layers\n",
        "pitch_embedding = Embedding(n_pitches, embed_dim, name='pitch_emb')(pitch_input)\n",
        "dur_embedding = Embedding(n_durs, embed_dim, name='dur_emb')(dur_input)\n",
        "\n",
        "# Merge embedding layers using a concatenation layer\n",
        "pitch_dur = Concatenate(axis=1, name='merge_pitch_dur')([pitch_embedding, dur_embedding])\n",
        "\n",
        "# Define LSTM layers\n",
        "lstm1 = LSTM(lstm1_n_units, name='lstm1', return_sequences=True)(pitch_dur)\n",
        "lstm2 = LSTM(lstm2_n_units, name='lstm2')(lstm1)\n",
        "\n",
        "# Define dense layer\n",
        "dense1 = Dense(dense1_n_units, name='dense1')(lstm2)\n",
        "\n",
        "# Define output layers\n",
        "pitch_output = Dense(n_pitches, activation='softmax', name='pitch_output')(dense1)\n",
        "dur_output = Dense(n_durs, activation='softmax', name='dur_output')(dense1)\n",
        "\n",
        "# Define model\n",
        "model2 = tf.keras.Model(inputs=[pitch_input, dur_input], outputs=[pitch_output, dur_output], name='model2')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfzlIYdFaKuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "4d089128-38ff-45d4-d784-4808a0134ebe"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "pitch_input (InputLayer)        [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dur_input (InputLayer)          [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "pitch_emb (Embedding)           (None, None, 12)     144         pitch_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dur_emb (Embedding)             (None, None, 12)     60          dur_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "merge_pitch_dur (Concatenate)   (None, None, 12)     0           pitch_emb[0][0]                  \n",
            "                                                                 dur_emb[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm1 (LSTM)                    (None, None, 128)    72192       merge_pitch_dur[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm2 (LSTM)                    (None, 64)           49408       lstm1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32)           2080        lstm2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pitch_output (Dense)            (None, 12)           396         dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dur_output (Dense)              (None, 5)            165         dense1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 124,445\n",
            "Trainable params: 124,445\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lBO6NV3aZ3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam()\n",
        "model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IxQA9ZSadLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "ff8a9160-dec6-4116-b483-a51a452aee1b"
      },
      "source": [
        "# dataset very large so step_per_epoch is reduced\n",
        "# TODO: currently the train-val split results in data leakage, that's okay for now, but a split on the song-level would solve that\n",
        "history = model2.fit(x=[X_p, X_d], y=[Y_p_ohe, Y_d_ohe], validation_split=0.01, batch_size=64, steps_per_epoch=8000, epochs=5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "8000/8000 [==============================] - 91s 11ms/step - loss: 2.8175 - pitch_output_loss: 2.1239 - dur_output_loss: 0.6936 - pitch_output_accuracy: 0.2361 - dur_output_accuracy: 0.7388 - val_loss: 2.3998 - val_pitch_output_loss: 1.7553 - val_dur_output_loss: 0.6446 - val_pitch_output_accuracy: 0.4075 - val_dur_output_accuracy: 0.7640\n",
            "Epoch 2/5\n",
            "8000/8000 [==============================] - 90s 11ms/step - loss: 2.5646 - pitch_output_loss: 1.8962 - dur_output_loss: 0.6684 - pitch_output_accuracy: 0.3399 - dur_output_accuracy: 0.7515 - val_loss: 2.2400 - val_pitch_output_loss: 1.5993 - val_dur_output_loss: 0.6407 - val_pitch_output_accuracy: 0.4869 - val_dur_output_accuracy: 0.7640\n",
            "Epoch 3/5\n",
            "8000/8000 [==============================] - 90s 11ms/step - loss: 2.4682 - pitch_output_loss: 1.8069 - dur_output_loss: 0.6613 - pitch_output_accuracy: 0.3866 - dur_output_accuracy: 0.7542 - val_loss: 2.1858 - val_pitch_output_loss: 1.5565 - val_dur_output_loss: 0.6294 - val_pitch_output_accuracy: 0.5056 - val_dur_output_accuracy: 0.7663\n",
            "Epoch 4/5\n",
            "8000/8000 [==============================] - 90s 11ms/step - loss: 2.4281 - pitch_output_loss: 1.7699 - dur_output_loss: 0.6582 - pitch_output_accuracy: 0.3997 - dur_output_accuracy: 0.7565 - val_loss: 2.1551 - val_pitch_output_loss: 1.5315 - val_dur_output_loss: 0.6236 - val_pitch_output_accuracy: 0.5129 - val_dur_output_accuracy: 0.7713\n",
            "Epoch 5/5\n",
            "8000/8000 [==============================] - 92s 11ms/step - loss: 2.3985 - pitch_output_loss: 1.7501 - dur_output_loss: 0.6484 - pitch_output_accuracy: 0.4062 - dur_output_accuracy: 0.7604 - val_loss: 2.1425 - val_pitch_output_loss: 1.5183 - val_dur_output_loss: 0.6242 - val_pitch_output_accuracy: 0.5140 - val_dur_output_accuracy: 0.7688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcAYThbpalda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save('model2.h5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnKNEL-LSmAs",
        "colab_type": "text"
      },
      "source": [
        "# Generate Some Music"
      ]
    },
    {
      "source": [
        "to generate music (note sequences), give a seed for pitches and durations, and specify the number of notes to generate, the maximum length of seed to use for generating each note, and the temperature for sampling notes from the model's predicted probability distribution"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "model1 = tf.keras.models.load_model('models/model1_1.h5')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Zd6ezeMBSmAt",
        "colab_type": "code",
        "colab": {}
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "0hPwKyzGSmAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_seq = utils.generate_sequence(model1, [0], [0], n_notes=64, seed_len=16, temp=1.25);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meVT1bHISmA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_p, gen_d = gen_seq # unpack pitches and durations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gWnAmDSmA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stream = utils.generate_stream(gen_p, gen_d) # generate a stream from the sequence of notes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HG_flwIYSmBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# play generated musice\n",
        "utils.music21.midi.realtime.StreamPlayer(stream).play()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl8uZUSYSmBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "utils.stream_to_midi(stream, 'generated_music/model1/0') # save stream to midi file"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}